<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="EoMT reveals Vision Transformers can perform image segmentation efficiently without task-specific components (CVPR 2025 Highlight)." />
  <meta name="keywords" content="EoMT, ViT, vision transformer, transformers, image segmentation, semantic segmentation, instance segmentation, panoptic segmentation, segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Your ViT is Secretly an Image Segmentation Model (CVPR 2025 Highlight)</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5TCTFJM8NG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5TCTFJM8NG');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="image/png" href="./static/images/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="./static/images/favicon.svg" />
  <link rel="shortcut icon" href="./static/images/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="./static/images/apple-touch-icon.png" />
  <meta name="apple-mobile-web-app-title" content="EoMT" />
  <link rel="manifest" href="./static/images/site.webmanifest" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-menu is-active">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.tue-mps.org">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <header class="has-text-centered mb-4">
            <h1 class="title is-1 publication-title">Your ViT is Secretly an Image Segmentation Model</h1>
            <h2 class="subtitle is-4">CVPR 2025 · Highlight Paper</h2>
          </header>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://tommiekerssies.com/" target="_blank" rel="noopener noreferrer">Tommie Kerssies</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=Pr4XHRAAAAAJ" target="_blank" rel="noopener noreferrer">Niccolò Cavagnero</a><sup>2,*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.de/citations?user=V0iMeYsAAAAJ" target="_blank" rel="noopener noreferrer">Alexander Hermans</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=q7sm490AAAAJ" target="_blank" rel="noopener noreferrer">Narges Norouzi</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.giuseppeaverta.me" target="_blank" rel="noopener noreferrer">Giuseppe Averta</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=ZcULDB0AAAAJ" target="_blank" rel="noopener noreferrer">Bastian Leibe</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.nl/citations?user=wy57br8AAAAJ" target="_blank" rel="noopener noreferrer">Gijs Dubbelman</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://ddegeus.github.io/" target="_blank" rel="noopener noreferrer">Daan de Geus</a><sup>1,3</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>&nbsp;Eindhoven University of Technology,</span>
            <span class="author-block"><sup>2</sup>&nbsp;Polytechnic of Turin,</span>
            <span class="author-block"><sup>3</sup>&nbsp;RWTH Aachen University</span>
          </div>
          <p class="has-text-centered mt-1" style="font-size: 0.6em;"> <em>* Work done while visiting RWTH.</em></p>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.19108"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tue-mps/eomt"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-vcentered">
        <div class="column">
          <figure class="image">
            <img src="./static/images/teaser_arch.svg" alt="Architecture Diagram">
          </figure>
        </div>
        <div class="column">
          <figure class="image">
            <img src="./static/images/teaser_plot.svg" alt="Performance Plot">
          </figure>
        </div>
      </div>
      <p class="has-text-centered" style="font-size: 0.6em;">
        [1] Bowen Cheng et al., <em>Masked-attention Mask Transformer for Universal Image Segmentation</em>, CVPR 2022.&nbsp;&nbsp;
        [2] Zhe Chen et al., <em>Vision Transformer Adapter for Dense Predictions</em>, ICLR 2023.
      </p>
    </div>
  </div>
</section>

<section class="hero is-light">
  <div class="hero-body container is-max-desktop">
    <!-- Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We present the <b>Encoder-only Mask Transformer (EoMT)</b>, a minimalist image segmentation model that repurposes a plain Vision Transformer (ViT) to jointly encode image patches and segmentation queries as tokens. No adapters. No decoders. Just the ViT.
          </p>
          <p>
            By leveraging large-scale pre-trained ViTs, EoMT achieves accuracy similar to state-of-the-art methods that rely on complex, task-specific components. At the same time, it is significantly faster thanks to its simplicity, for example up to 4× faster with ViT-L.  
          <p>
            Turns out, <em>your ViT is secretly an image segmentation model</em>. EoMT shows that architectural complexity isn’t necessary, plain Transformer power is all you need.
          </p>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Encoder-only Mask Transformer (EoMT)</h2>
        <img src="./static/images/arch.svg" alt="Method Figure" style="width:100%; max-width: 500px; margin-top:1em;" />
      </div>
    </div>
  </div>
</section>

<div class="container is-max-desktop content">
  <div class="has-text-centered">
    <h2 class="title">Citation</h2>
  </div>
  <pre><code>@inproceedings{kerssies2025eomt,
  author     = {Kerssies, Tommie and Cavagnero, Niccolò and Hermans, Alexander and Norouzi, Narges and Averta, Giuseppe and Leibe, Bastian and Dubbelman, Gijs and de Geus, Daan},
  title      = {Your ViT is Secretly an Image Segmentation Model},
  booktitle  = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year       = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer py-6">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2503.19108" target="_blank" rel="noopener noreferrer">
        <i class="ai ai-arxiv fa-sm"></i>
      </a>
      <a class="icon-link" href="https://github.com/tue-mps" class="external-link" disabled>
        <i class="fab fa-github fa-sm"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content is-small has-text-centered">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons BY-SA 4.0 License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
