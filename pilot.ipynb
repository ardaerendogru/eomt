{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied LoRA to the first 20 blocks with rank 32.\n",
      "trainable params: 53014528 || all params: 307412992 || trainable%: 17.25\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models import EoMT\n",
    "from models import ViT\n",
    "model = EoMT(\n",
    "    encoder=ViT(\n",
    "        img_size=(640, 640),\n",
    "        patch_size=16,\n",
    "        backbone_name=\"vit_large_patch14_reg4_dinov2\",\n",
    "        lora_r = 32,\n",
    "        num_lora_free_blocks = 4,  # Number of final blocks to exclude from LoRA\n",
    "        lora_class= \"LoRA\",\n",
    "        ),num_classes=1000,num_q=200,num_blocks=4,masked_attn_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = [k.replace('qkv','qkv.LoRA.qkv')  for k, v in model.state_dict().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attn_mask_probs',\n",
       " 'encoder.pixel_mean',\n",
       " 'encoder.pixel_std',\n",
       " 'encoder.backbone.cls_token',\n",
       " 'encoder.backbone.reg_token',\n",
       " 'encoder.backbone.pos_embed',\n",
       " 'encoder.backbone.patch_embed.proj.weight',\n",
       " 'encoder.backbone.patch_embed.proj.bias',\n",
       " 'encoder.backbone.blocks.0.norm1.weight',\n",
       " 'encoder.backbone.blocks.0.norm1.bias',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.0.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.0.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.0.ls1.gamma',\n",
       " 'encoder.backbone.blocks.0.norm2.weight',\n",
       " 'encoder.backbone.blocks.0.norm2.bias',\n",
       " 'encoder.backbone.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.0.ls2.gamma',\n",
       " 'encoder.backbone.blocks.1.norm1.weight',\n",
       " 'encoder.backbone.blocks.1.norm1.bias',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.1.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.1.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.1.ls1.gamma',\n",
       " 'encoder.backbone.blocks.1.norm2.weight',\n",
       " 'encoder.backbone.blocks.1.norm2.bias',\n",
       " 'encoder.backbone.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.1.ls2.gamma',\n",
       " 'encoder.backbone.blocks.2.norm1.weight',\n",
       " 'encoder.backbone.blocks.2.norm1.bias',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.2.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.2.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.2.ls1.gamma',\n",
       " 'encoder.backbone.blocks.2.norm2.weight',\n",
       " 'encoder.backbone.blocks.2.norm2.bias',\n",
       " 'encoder.backbone.blocks.2.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.2.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.2.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.2.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.2.ls2.gamma',\n",
       " 'encoder.backbone.blocks.3.norm1.weight',\n",
       " 'encoder.backbone.blocks.3.norm1.bias',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.3.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.3.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.3.ls1.gamma',\n",
       " 'encoder.backbone.blocks.3.norm2.weight',\n",
       " 'encoder.backbone.blocks.3.norm2.bias',\n",
       " 'encoder.backbone.blocks.3.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.3.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.3.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.3.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.3.ls2.gamma',\n",
       " 'encoder.backbone.blocks.4.norm1.weight',\n",
       " 'encoder.backbone.blocks.4.norm1.bias',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.4.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.4.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.4.ls1.gamma',\n",
       " 'encoder.backbone.blocks.4.norm2.weight',\n",
       " 'encoder.backbone.blocks.4.norm2.bias',\n",
       " 'encoder.backbone.blocks.4.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.4.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.4.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.4.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.4.ls2.gamma',\n",
       " 'encoder.backbone.blocks.5.norm1.weight',\n",
       " 'encoder.backbone.blocks.5.norm1.bias',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.5.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.5.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.5.ls1.gamma',\n",
       " 'encoder.backbone.blocks.5.norm2.weight',\n",
       " 'encoder.backbone.blocks.5.norm2.bias',\n",
       " 'encoder.backbone.blocks.5.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.5.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.5.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.5.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.5.ls2.gamma',\n",
       " 'encoder.backbone.blocks.6.norm1.weight',\n",
       " 'encoder.backbone.blocks.6.norm1.bias',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.6.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.6.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.6.ls1.gamma',\n",
       " 'encoder.backbone.blocks.6.norm2.weight',\n",
       " 'encoder.backbone.blocks.6.norm2.bias',\n",
       " 'encoder.backbone.blocks.6.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.6.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.6.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.6.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.6.ls2.gamma',\n",
       " 'encoder.backbone.blocks.7.norm1.weight',\n",
       " 'encoder.backbone.blocks.7.norm1.bias',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.7.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.7.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.7.ls1.gamma',\n",
       " 'encoder.backbone.blocks.7.norm2.weight',\n",
       " 'encoder.backbone.blocks.7.norm2.bias',\n",
       " 'encoder.backbone.blocks.7.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.7.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.7.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.7.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.7.ls2.gamma',\n",
       " 'encoder.backbone.blocks.8.norm1.weight',\n",
       " 'encoder.backbone.blocks.8.norm1.bias',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.8.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.8.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.8.ls1.gamma',\n",
       " 'encoder.backbone.blocks.8.norm2.weight',\n",
       " 'encoder.backbone.blocks.8.norm2.bias',\n",
       " 'encoder.backbone.blocks.8.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.8.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.8.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.8.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.8.ls2.gamma',\n",
       " 'encoder.backbone.blocks.9.norm1.weight',\n",
       " 'encoder.backbone.blocks.9.norm1.bias',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.9.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.9.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.9.ls1.gamma',\n",
       " 'encoder.backbone.blocks.9.norm2.weight',\n",
       " 'encoder.backbone.blocks.9.norm2.bias',\n",
       " 'encoder.backbone.blocks.9.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.9.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.9.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.9.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.9.ls2.gamma',\n",
       " 'encoder.backbone.blocks.10.norm1.weight',\n",
       " 'encoder.backbone.blocks.10.norm1.bias',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.10.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.10.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.10.ls1.gamma',\n",
       " 'encoder.backbone.blocks.10.norm2.weight',\n",
       " 'encoder.backbone.blocks.10.norm2.bias',\n",
       " 'encoder.backbone.blocks.10.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.10.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.10.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.10.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.10.ls2.gamma',\n",
       " 'encoder.backbone.blocks.11.norm1.weight',\n",
       " 'encoder.backbone.blocks.11.norm1.bias',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.11.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.11.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.11.ls1.gamma',\n",
       " 'encoder.backbone.blocks.11.norm2.weight',\n",
       " 'encoder.backbone.blocks.11.norm2.bias',\n",
       " 'encoder.backbone.blocks.11.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.11.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.11.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.11.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.11.ls2.gamma',\n",
       " 'encoder.backbone.blocks.12.norm1.weight',\n",
       " 'encoder.backbone.blocks.12.norm1.bias',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.12.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.12.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.12.ls1.gamma',\n",
       " 'encoder.backbone.blocks.12.norm2.weight',\n",
       " 'encoder.backbone.blocks.12.norm2.bias',\n",
       " 'encoder.backbone.blocks.12.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.12.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.12.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.12.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.12.ls2.gamma',\n",
       " 'encoder.backbone.blocks.13.norm1.weight',\n",
       " 'encoder.backbone.blocks.13.norm1.bias',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.13.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.13.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.13.ls1.gamma',\n",
       " 'encoder.backbone.blocks.13.norm2.weight',\n",
       " 'encoder.backbone.blocks.13.norm2.bias',\n",
       " 'encoder.backbone.blocks.13.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.13.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.13.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.13.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.13.ls2.gamma',\n",
       " 'encoder.backbone.blocks.14.norm1.weight',\n",
       " 'encoder.backbone.blocks.14.norm1.bias',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.14.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.14.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.14.ls1.gamma',\n",
       " 'encoder.backbone.blocks.14.norm2.weight',\n",
       " 'encoder.backbone.blocks.14.norm2.bias',\n",
       " 'encoder.backbone.blocks.14.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.14.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.14.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.14.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.14.ls2.gamma',\n",
       " 'encoder.backbone.blocks.15.norm1.weight',\n",
       " 'encoder.backbone.blocks.15.norm1.bias',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.15.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.15.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.15.ls1.gamma',\n",
       " 'encoder.backbone.blocks.15.norm2.weight',\n",
       " 'encoder.backbone.blocks.15.norm2.bias',\n",
       " 'encoder.backbone.blocks.15.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.15.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.15.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.15.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.15.ls2.gamma',\n",
       " 'encoder.backbone.blocks.16.norm1.weight',\n",
       " 'encoder.backbone.blocks.16.norm1.bias',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.16.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.16.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.16.ls1.gamma',\n",
       " 'encoder.backbone.blocks.16.norm2.weight',\n",
       " 'encoder.backbone.blocks.16.norm2.bias',\n",
       " 'encoder.backbone.blocks.16.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.16.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.16.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.16.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.16.ls2.gamma',\n",
       " 'encoder.backbone.blocks.17.norm1.weight',\n",
       " 'encoder.backbone.blocks.17.norm1.bias',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.17.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.17.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.17.ls1.gamma',\n",
       " 'encoder.backbone.blocks.17.norm2.weight',\n",
       " 'encoder.backbone.blocks.17.norm2.bias',\n",
       " 'encoder.backbone.blocks.17.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.17.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.17.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.17.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.17.ls2.gamma',\n",
       " 'encoder.backbone.blocks.18.norm1.weight',\n",
       " 'encoder.backbone.blocks.18.norm1.bias',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.18.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.18.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.18.ls1.gamma',\n",
       " 'encoder.backbone.blocks.18.norm2.weight',\n",
       " 'encoder.backbone.blocks.18.norm2.bias',\n",
       " 'encoder.backbone.blocks.18.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.18.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.18.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.18.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.18.ls2.gamma',\n",
       " 'encoder.backbone.blocks.19.norm1.weight',\n",
       " 'encoder.backbone.blocks.19.norm1.bias',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.qkv.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.qkv.bias',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.19.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.19.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.19.ls1.gamma',\n",
       " 'encoder.backbone.blocks.19.norm2.weight',\n",
       " 'encoder.backbone.blocks.19.norm2.bias',\n",
       " 'encoder.backbone.blocks.19.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.19.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.19.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.19.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.19.ls2.gamma',\n",
       " 'encoder.backbone.blocks.20.norm1.weight',\n",
       " 'encoder.backbone.blocks.20.norm1.bias',\n",
       " 'encoder.backbone.blocks.20.attn.qkv.weight',\n",
       " 'encoder.backbone.blocks.20.attn.qkv.bias',\n",
       " 'encoder.backbone.blocks.20.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.20.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.20.ls1.gamma',\n",
       " 'encoder.backbone.blocks.20.norm2.weight',\n",
       " 'encoder.backbone.blocks.20.norm2.bias',\n",
       " 'encoder.backbone.blocks.20.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.20.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.20.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.20.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.20.ls2.gamma',\n",
       " 'encoder.backbone.blocks.21.norm1.weight',\n",
       " 'encoder.backbone.blocks.21.norm1.bias',\n",
       " 'encoder.backbone.blocks.21.attn.qkv.weight',\n",
       " 'encoder.backbone.blocks.21.attn.qkv.bias',\n",
       " 'encoder.backbone.blocks.21.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.21.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.21.ls1.gamma',\n",
       " 'encoder.backbone.blocks.21.norm2.weight',\n",
       " 'encoder.backbone.blocks.21.norm2.bias',\n",
       " 'encoder.backbone.blocks.21.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.21.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.21.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.21.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.21.ls2.gamma',\n",
       " 'encoder.backbone.blocks.22.norm1.weight',\n",
       " 'encoder.backbone.blocks.22.norm1.bias',\n",
       " 'encoder.backbone.blocks.22.attn.qkv.weight',\n",
       " 'encoder.backbone.blocks.22.attn.qkv.bias',\n",
       " 'encoder.backbone.blocks.22.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.22.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.22.ls1.gamma',\n",
       " 'encoder.backbone.blocks.22.norm2.weight',\n",
       " 'encoder.backbone.blocks.22.norm2.bias',\n",
       " 'encoder.backbone.blocks.22.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.22.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.22.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.22.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.22.ls2.gamma',\n",
       " 'encoder.backbone.blocks.23.norm1.weight',\n",
       " 'encoder.backbone.blocks.23.norm1.bias',\n",
       " 'encoder.backbone.blocks.23.attn.qkv.weight',\n",
       " 'encoder.backbone.blocks.23.attn.qkv.bias',\n",
       " 'encoder.backbone.blocks.23.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.23.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.23.ls1.gamma',\n",
       " 'encoder.backbone.blocks.23.norm2.weight',\n",
       " 'encoder.backbone.blocks.23.norm2.bias',\n",
       " 'encoder.backbone.blocks.23.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.23.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.23.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.23.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.23.ls2.gamma',\n",
       " 'encoder.backbone.norm.weight',\n",
       " 'encoder.backbone.norm.bias',\n",
       " 'q.weight',\n",
       " 'class_head.weight',\n",
       " 'class_head.bias',\n",
       " 'mask_head.0.weight',\n",
       " 'mask_head.0.bias',\n",
       " 'mask_head.2.weight',\n",
       " 'mask_head.2.bias',\n",
       " 'mask_head.4.weight',\n",
       " 'mask_head.4.bias',\n",
       " 'upscale.0.conv1.weight',\n",
       " 'upscale.0.conv1.bias',\n",
       " 'upscale.0.conv2.weight',\n",
       " 'upscale.0.norm.weight',\n",
       " 'upscale.0.norm.bias',\n",
       " 'upscale.1.conv1.weight',\n",
       " 'upscale.1.conv1.bias',\n",
       " 'upscale.1.conv2.weight',\n",
       " 'upscale.1.norm.weight',\n",
       " 'upscale.1.norm.bias']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_keys = [k for k, v in model.state_dict().items()]\n",
    "original_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attn_mask_probs',\n",
       " 'encoder.pixel_mean',\n",
       " 'encoder.pixel_std',\n",
       " 'encoder.backbone.cls_token',\n",
       " 'encoder.backbone.reg_token',\n",
       " 'encoder.backbone.pos_embed',\n",
       " 'encoder.backbone.patch_embed.proj.weight',\n",
       " 'encoder.backbone.patch_embed.proj.bias',\n",
       " 'encoder.backbone.blocks.0.norm1.weight',\n",
       " 'encoder.backbone.blocks.0.norm1.bias',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.0.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.0.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.0.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.0.ls1.gamma',\n",
       " 'encoder.backbone.blocks.0.norm2.weight',\n",
       " 'encoder.backbone.blocks.0.norm2.bias',\n",
       " 'encoder.backbone.blocks.0.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.0.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.0.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.0.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.0.ls2.gamma',\n",
       " 'encoder.backbone.blocks.1.norm1.weight',\n",
       " 'encoder.backbone.blocks.1.norm1.bias',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.1.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.1.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.1.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.1.ls1.gamma',\n",
       " 'encoder.backbone.blocks.1.norm2.weight',\n",
       " 'encoder.backbone.blocks.1.norm2.bias',\n",
       " 'encoder.backbone.blocks.1.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.1.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.1.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.1.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.1.ls2.gamma',\n",
       " 'encoder.backbone.blocks.2.norm1.weight',\n",
       " 'encoder.backbone.blocks.2.norm1.bias',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.2.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.2.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.2.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.2.ls1.gamma',\n",
       " 'encoder.backbone.blocks.2.norm2.weight',\n",
       " 'encoder.backbone.blocks.2.norm2.bias',\n",
       " 'encoder.backbone.blocks.2.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.2.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.2.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.2.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.2.ls2.gamma',\n",
       " 'encoder.backbone.blocks.3.norm1.weight',\n",
       " 'encoder.backbone.blocks.3.norm1.bias',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.3.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.3.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.3.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.3.ls1.gamma',\n",
       " 'encoder.backbone.blocks.3.norm2.weight',\n",
       " 'encoder.backbone.blocks.3.norm2.bias',\n",
       " 'encoder.backbone.blocks.3.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.3.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.3.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.3.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.3.ls2.gamma',\n",
       " 'encoder.backbone.blocks.4.norm1.weight',\n",
       " 'encoder.backbone.blocks.4.norm1.bias',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.4.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.4.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.4.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.4.ls1.gamma',\n",
       " 'encoder.backbone.blocks.4.norm2.weight',\n",
       " 'encoder.backbone.blocks.4.norm2.bias',\n",
       " 'encoder.backbone.blocks.4.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.4.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.4.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.4.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.4.ls2.gamma',\n",
       " 'encoder.backbone.blocks.5.norm1.weight',\n",
       " 'encoder.backbone.blocks.5.norm1.bias',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.5.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.5.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.5.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.5.ls1.gamma',\n",
       " 'encoder.backbone.blocks.5.norm2.weight',\n",
       " 'encoder.backbone.blocks.5.norm2.bias',\n",
       " 'encoder.backbone.blocks.5.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.5.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.5.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.5.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.5.ls2.gamma',\n",
       " 'encoder.backbone.blocks.6.norm1.weight',\n",
       " 'encoder.backbone.blocks.6.norm1.bias',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.6.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.6.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.6.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.6.ls1.gamma',\n",
       " 'encoder.backbone.blocks.6.norm2.weight',\n",
       " 'encoder.backbone.blocks.6.norm2.bias',\n",
       " 'encoder.backbone.blocks.6.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.6.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.6.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.6.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.6.ls2.gamma',\n",
       " 'encoder.backbone.blocks.7.norm1.weight',\n",
       " 'encoder.backbone.blocks.7.norm1.bias',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.7.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.7.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.7.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.7.ls1.gamma',\n",
       " 'encoder.backbone.blocks.7.norm2.weight',\n",
       " 'encoder.backbone.blocks.7.norm2.bias',\n",
       " 'encoder.backbone.blocks.7.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.7.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.7.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.7.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.7.ls2.gamma',\n",
       " 'encoder.backbone.blocks.8.norm1.weight',\n",
       " 'encoder.backbone.blocks.8.norm1.bias',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.8.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.8.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.8.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.8.ls1.gamma',\n",
       " 'encoder.backbone.blocks.8.norm2.weight',\n",
       " 'encoder.backbone.blocks.8.norm2.bias',\n",
       " 'encoder.backbone.blocks.8.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.8.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.8.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.8.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.8.ls2.gamma',\n",
       " 'encoder.backbone.blocks.9.norm1.weight',\n",
       " 'encoder.backbone.blocks.9.norm1.bias',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.9.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.9.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.9.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.9.ls1.gamma',\n",
       " 'encoder.backbone.blocks.9.norm2.weight',\n",
       " 'encoder.backbone.blocks.9.norm2.bias',\n",
       " 'encoder.backbone.blocks.9.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.9.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.9.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.9.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.9.ls2.gamma',\n",
       " 'encoder.backbone.blocks.10.norm1.weight',\n",
       " 'encoder.backbone.blocks.10.norm1.bias',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.10.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.10.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.10.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.10.ls1.gamma',\n",
       " 'encoder.backbone.blocks.10.norm2.weight',\n",
       " 'encoder.backbone.blocks.10.norm2.bias',\n",
       " 'encoder.backbone.blocks.10.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.10.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.10.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.10.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.10.ls2.gamma',\n",
       " 'encoder.backbone.blocks.11.norm1.weight',\n",
       " 'encoder.backbone.blocks.11.norm1.bias',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.11.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.11.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.11.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.11.ls1.gamma',\n",
       " 'encoder.backbone.blocks.11.norm2.weight',\n",
       " 'encoder.backbone.blocks.11.norm2.bias',\n",
       " 'encoder.backbone.blocks.11.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.11.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.11.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.11.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.11.ls2.gamma',\n",
       " 'encoder.backbone.blocks.12.norm1.weight',\n",
       " 'encoder.backbone.blocks.12.norm1.bias',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.12.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.12.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.12.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.12.ls1.gamma',\n",
       " 'encoder.backbone.blocks.12.norm2.weight',\n",
       " 'encoder.backbone.blocks.12.norm2.bias',\n",
       " 'encoder.backbone.blocks.12.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.12.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.12.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.12.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.12.ls2.gamma',\n",
       " 'encoder.backbone.blocks.13.norm1.weight',\n",
       " 'encoder.backbone.blocks.13.norm1.bias',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.13.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.13.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.13.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.13.ls1.gamma',\n",
       " 'encoder.backbone.blocks.13.norm2.weight',\n",
       " 'encoder.backbone.blocks.13.norm2.bias',\n",
       " 'encoder.backbone.blocks.13.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.13.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.13.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.13.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.13.ls2.gamma',\n",
       " 'encoder.backbone.blocks.14.norm1.weight',\n",
       " 'encoder.backbone.blocks.14.norm1.bias',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.14.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.14.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.14.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.14.ls1.gamma',\n",
       " 'encoder.backbone.blocks.14.norm2.weight',\n",
       " 'encoder.backbone.blocks.14.norm2.bias',\n",
       " 'encoder.backbone.blocks.14.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.14.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.14.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.14.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.14.ls2.gamma',\n",
       " 'encoder.backbone.blocks.15.norm1.weight',\n",
       " 'encoder.backbone.blocks.15.norm1.bias',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.15.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.15.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.15.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.15.ls1.gamma',\n",
       " 'encoder.backbone.blocks.15.norm2.weight',\n",
       " 'encoder.backbone.blocks.15.norm2.bias',\n",
       " 'encoder.backbone.blocks.15.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.15.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.15.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.15.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.15.ls2.gamma',\n",
       " 'encoder.backbone.blocks.16.norm1.weight',\n",
       " 'encoder.backbone.blocks.16.norm1.bias',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.16.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.16.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.16.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.16.ls1.gamma',\n",
       " 'encoder.backbone.blocks.16.norm2.weight',\n",
       " 'encoder.backbone.blocks.16.norm2.bias',\n",
       " 'encoder.backbone.blocks.16.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.16.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.16.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.16.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.16.ls2.gamma',\n",
       " 'encoder.backbone.blocks.17.norm1.weight',\n",
       " 'encoder.backbone.blocks.17.norm1.bias',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.17.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.17.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.17.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.17.ls1.gamma',\n",
       " 'encoder.backbone.blocks.17.norm2.weight',\n",
       " 'encoder.backbone.blocks.17.norm2.bias',\n",
       " 'encoder.backbone.blocks.17.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.17.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.17.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.17.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.17.ls2.gamma',\n",
       " 'encoder.backbone.blocks.18.norm1.weight',\n",
       " 'encoder.backbone.blocks.18.norm1.bias',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.18.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.18.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.18.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.18.ls1.gamma',\n",
       " 'encoder.backbone.blocks.18.norm2.weight',\n",
       " 'encoder.backbone.blocks.18.norm2.bias',\n",
       " 'encoder.backbone.blocks.18.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.18.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.18.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.18.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.18.ls2.gamma',\n",
       " 'encoder.backbone.blocks.19.norm1.weight',\n",
       " 'encoder.backbone.blocks.19.norm1.bias',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.linear_a_q.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.linear_b_q.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.linear_a_v.weight',\n",
       " 'encoder.backbone.blocks.19.attn.qkv.LoRA.qkv.linear_b_v.weight',\n",
       " 'encoder.backbone.blocks.19.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.19.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.19.ls1.gamma',\n",
       " 'encoder.backbone.blocks.19.norm2.weight',\n",
       " 'encoder.backbone.blocks.19.norm2.bias',\n",
       " 'encoder.backbone.blocks.19.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.19.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.19.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.19.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.19.ls2.gamma',\n",
       " 'encoder.backbone.blocks.20.norm1.weight',\n",
       " 'encoder.backbone.blocks.20.norm1.bias',\n",
       " 'encoder.backbone.blocks.20.attn.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.20.attn.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.20.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.20.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.20.ls1.gamma',\n",
       " 'encoder.backbone.blocks.20.norm2.weight',\n",
       " 'encoder.backbone.blocks.20.norm2.bias',\n",
       " 'encoder.backbone.blocks.20.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.20.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.20.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.20.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.20.ls2.gamma',\n",
       " 'encoder.backbone.blocks.21.norm1.weight',\n",
       " 'encoder.backbone.blocks.21.norm1.bias',\n",
       " 'encoder.backbone.blocks.21.attn.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.21.attn.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.21.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.21.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.21.ls1.gamma',\n",
       " 'encoder.backbone.blocks.21.norm2.weight',\n",
       " 'encoder.backbone.blocks.21.norm2.bias',\n",
       " 'encoder.backbone.blocks.21.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.21.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.21.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.21.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.21.ls2.gamma',\n",
       " 'encoder.backbone.blocks.22.norm1.weight',\n",
       " 'encoder.backbone.blocks.22.norm1.bias',\n",
       " 'encoder.backbone.blocks.22.attn.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.22.attn.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.22.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.22.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.22.ls1.gamma',\n",
       " 'encoder.backbone.blocks.22.norm2.weight',\n",
       " 'encoder.backbone.blocks.22.norm2.bias',\n",
       " 'encoder.backbone.blocks.22.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.22.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.22.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.22.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.22.ls2.gamma',\n",
       " 'encoder.backbone.blocks.23.norm1.weight',\n",
       " 'encoder.backbone.blocks.23.norm1.bias',\n",
       " 'encoder.backbone.blocks.23.attn.qkv.LoRA.qkv.weight',\n",
       " 'encoder.backbone.blocks.23.attn.qkv.LoRA.qkv.bias',\n",
       " 'encoder.backbone.blocks.23.attn.proj.weight',\n",
       " 'encoder.backbone.blocks.23.attn.proj.bias',\n",
       " 'encoder.backbone.blocks.23.ls1.gamma',\n",
       " 'encoder.backbone.blocks.23.norm2.weight',\n",
       " 'encoder.backbone.blocks.23.norm2.bias',\n",
       " 'encoder.backbone.blocks.23.mlp.fc1.weight',\n",
       " 'encoder.backbone.blocks.23.mlp.fc1.bias',\n",
       " 'encoder.backbone.blocks.23.mlp.fc2.weight',\n",
       " 'encoder.backbone.blocks.23.mlp.fc2.bias',\n",
       " 'encoder.backbone.blocks.23.ls2.gamma',\n",
       " 'encoder.backbone.norm.weight',\n",
       " 'encoder.backbone.norm.bias',\n",
       " 'q.weight',\n",
       " 'class_head.weight',\n",
       " 'class_head.bias',\n",
       " 'mask_head.0.weight',\n",
       " 'mask_head.0.bias',\n",
       " 'mask_head.2.weight',\n",
       " 'mask_head.2.bias',\n",
       " 'mask_head.4.weight',\n",
       " 'mask_head.4.bias',\n",
       " 'upscale.0.conv1.weight',\n",
       " 'upscale.0.conv1.bias',\n",
       " 'upscale.0.conv2.weight',\n",
       " 'upscale.0.norm.weight',\n",
       " 'upscale.0.norm.bias',\n",
       " 'upscale.1.conv1.weight',\n",
       " 'upscale.1.conv1.bias',\n",
       " 'upscale.1.conv2.weight',\n",
       " 'upscale.1.norm.weight',\n",
       " 'upscale.1.norm.bias']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EoMT(\n",
       "  (encoder): ViT(\n",
       "    (backbone): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (q): Embedding(200, 1024)\n",
       "  (class_head): Linear(in_features=1024, out_features=1001, bias=True)\n",
       "  (mask_head): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (upscale): Sequential(\n",
       "    (0): ScaleBlock(\n",
       "      (conv1): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): ScaleBlock(\n",
       "      (conv1): ConvTranspose2d(1024, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (act): GELU(approximate='none')\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace('qkv','qkv.LoRA.qkv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EoMT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
