trainer:
  max_epochs: 5000
  check_val_every_n_epoch: 1000

  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt_ade_one"
      name: "ade20k_panoptic_eomt_large_640"
model:
  class_path: training.mask_classification_panoptic.MaskClassificationPanoptic
  init_args:
    attn_mask_annealing_enabled: True
    attn_mask_annealing_start_steps: [833, 1666, 2499, 3332]
    attn_mask_annealing_end_steps: [1666, 2499, 3332, 4165]
    finetuning_type: "all"
    lr: 1.00E-04
    lr_head_multiplier: 1
    network:
      class_path: models.eomt.EoMT
      init_args:
        num_q: 200
        encoder:
          class_path: models.vit.ViT
          # init_args:
          #   lora_r: 64                                                                                   
          #   lora_class: ProLoRA
          #   num_lora_free_blocks: 0  

data:
  class_path: datasets.ade20k_panoptic.ADE20KPanoptic
  init_args:
    num_workers: 8
    stuff_classes: [0, 1, 2, 3, 4, 5, 6, 9, 11, 13, 16, 17, 21, 25, 26, 28, 29, 34, 40, 46, 48, 51, 52, 54, 59, 60, 61, 63, 68, 77, 79, 84, 91, 94, 96, 99, 100, 101, 105, 106, 109, 113, 114, 117, 122, 128, 131, 140, 141, 145]
